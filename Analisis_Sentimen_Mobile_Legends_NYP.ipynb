{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ1EBwiDRGGAjaCEXCQgYp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaufalYogaPratama/analisis-sentimen-MLBB/blob/main/Analisis_Sentimen_Mobile_Legends_NYP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analisis Sentimen mobile Legends: Bang Bang**"
      ],
      "metadata": {
        "id": "OHPip_wTPOY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Library"
      ],
      "metadata": {
        "id": "vcjbYr2mPWrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPfAIMJDPGHf",
        "outputId": "fef917b6-d732-4f12-c6a7-d752691424a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n",
            "Instalasi selesai!\n"
          ]
        }
      ],
      "source": [
        "!pip install google-play-scraper pandas tqdm\n",
        "print(\"Instalasi selesai!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "oVEVavblPkoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google_play_scraper import Sort, reviews\n",
        "from tqdm import tqdm\n",
        "import logging"
      ],
      "metadata": {
        "id": "H77KMndvPnML"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping Process"
      ],
      "metadata": {
        "id": "3-rIuYIsPo0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup logging dasar\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- Konfigurasi Scraping ---\n",
        "# ID Aplikasi Mobile Legend: Bang Bang di Google Play Store\n",
        "APP_ID = 'com.mobile.legends'\n",
        "# Jumlah ulasan yang ingin kita kumpulkan\n",
        "REVIEW_COUNT = 12000 # Kita ambil lebih untuk cadangan jika ada data duplikat/kosong\n",
        "# Nama file output\n",
        "OUTPUT_FILENAME = 'mobile_legends_reviews.csv'\n",
        "\n",
        "logging.info(f\"Memulai scraping untuk aplikasi: {APP_ID}\")\n",
        "\n",
        "# Melakukan scraping ulasan\n",
        "# Library ini akan menangani paginasi secara otomatis untuk mengambil jumlah yang kita minta\n",
        "result, _ = reviews(\n",
        "    APP_ID,\n",
        "    lang='id',           # Bahasa: Indonesia\n",
        "    country='id',        # Negara: Indonesia\n",
        "    sort=Sort.NEWEST,    # Urutkan berdasarkan yang paling baru\n",
        "    count=REVIEW_COUNT,\n",
        "    filter_score_with=None # Ambil semua skor dari 1 sampai 5\n",
        ")\n",
        "\n",
        "if not result:\n",
        "    logging.warning(\"Tidak ada ulasan yang berhasil di-scrape.\")\n",
        "else:\n",
        "    # Konversi hasil ke DataFrame pandas\n",
        "    df_reviews = pd.DataFrame(result)\n",
        "\n",
        "    # Pilih hanya kolom yang relevan untuk proyek kita\n",
        "    df_final = df_reviews[['content', 'score', 'at']].copy()\n",
        "    df_final.rename(columns={'content': 'review_text', 'score': 'rating', 'at': 'review_date'}, inplace=True)\n",
        "\n",
        "    # Membersihkan data dari baris yang tidak memiliki teks ulasan\n",
        "    df_final.dropna(subset=['review_text'], inplace=True)\n",
        "\n",
        "    # Menghapus ulasan yang duplikat\n",
        "    df_final.drop_duplicates(subset=['review_text'], keep='first', inplace=True)\n",
        "\n",
        "    logging.info(f\"Berhasil mengumpulkan {len(df_final)} ulasan unik.\")\n",
        "\n",
        "    # Menyimpan DataFrame ke file CSV di lingkungan Colab\n",
        "    df_final.to_csv(OUTPUT_FILENAME, index=False, encoding='utf-8')\n",
        "\n",
        "    logging.info(f\"Dataset berhasil disimpan sebagai '{OUTPUT_FILENAME}'.\")\n",
        "\n",
        "    # Menampilkan 5 baris pertama dari dataset\n",
        "    print(\"\\nBerikut adalah 5 sampel data pertama:\")\n",
        "    print(df_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnLOuT_KPok2",
        "outputId": "1ad70f35-d966-41c3-c04a-8f10a2c3b0ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Berikut adalah 5 sampel data pertama:\n",
            "                                         review_text  rating  \\\n",
            "0  maaf kk semua player sekalu afk terus dan saya...       1   \n",
            "1                           DARK SYSTEM SEMUA ISINYA       1   \n",
            "2                           kurangin dark sistem nya       5   \n",
            "3  apalah ini game jaringan bagus, udah pake wifi...       1   \n",
            "4  nontonn ajing buat meta line banyak drak siste...       1   \n",
            "\n",
            "          review_date  \n",
            "0 2025-06-25 17:20:47  \n",
            "1 2025-06-25 17:20:44  \n",
            "2 2025-06-25 17:20:31  \n",
            "3 2025-06-25 17:20:21  \n",
            "4 2025-06-25 17:19:11  \n"
          ]
        }
      ]
    }
  ]
}