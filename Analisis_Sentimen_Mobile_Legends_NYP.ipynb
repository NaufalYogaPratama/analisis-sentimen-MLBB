{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyBvaKldZGA0wIcOqNCxwY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaufalYogaPratama/analisis-sentimen-MLBB/blob/main/Analisis_Sentimen_Mobile_Legends_NYP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analisis Sentimen mobile Legends: Bang Bang**"
      ],
      "metadata": {
        "id": "OHPip_wTPOY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Library"
      ],
      "metadata": {
        "id": "vcjbYr2mPWrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPfAIMJDPGHf",
        "outputId": "74176b33-bf85-4f12-cb1a-420f12a13a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-play-scraper in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Instalasi selesai!\n"
          ]
        }
      ],
      "source": [
        "!pip install google-play-scraper pandas tqdm\n",
        "!pip install Sastrawi\n",
        "print(\"Instalasi selesai!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "oVEVavblPkoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google_play_scraper import Sort, reviews\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import re\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "H77KMndvPnML"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping Process"
      ],
      "metadata": {
        "id": "3-rIuYIsPo0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup logging dasar\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- Konfigurasi Scraping ---\n",
        "# ID Aplikasi Mobile Legend: Bang Bang di Google Play Store\n",
        "APP_ID = 'com.mobile.legends'\n",
        "# Jumlah ulasan yang ingin kita kumpulkan\n",
        "REVIEW_COUNT = 12000 # Kita ambil lebih untuk cadangan jika ada data duplikat/kosong\n",
        "# Nama file output\n",
        "OUTPUT_FILENAME = 'mobile_legends_reviews.csv'\n",
        "\n",
        "logging.info(f\"Memulai scraping untuk aplikasi: {APP_ID}\")\n",
        "\n",
        "# Melakukan scraping ulasan\n",
        "# Library ini akan menangani paginasi secara otomatis untuk mengambil jumlah yang kita minta\n",
        "result, _ = reviews(\n",
        "    APP_ID,\n",
        "    lang='id',           # Bahasa: Indonesia\n",
        "    country='id',        # Negara: Indonesia\n",
        "    sort=Sort.NEWEST,    # Urutkan berdasarkan yang paling baru\n",
        "    count=REVIEW_COUNT,\n",
        "    filter_score_with=None # Ambil semua skor dari 1 sampai 5\n",
        ")\n",
        "\n",
        "if not result:\n",
        "    logging.warning(\"Tidak ada ulasan yang berhasil di-scrape.\")\n",
        "else:\n",
        "    # Konversi hasil ke DataFrame pandas\n",
        "    df_reviews = pd.DataFrame(result)\n",
        "\n",
        "    # Pilih hanya kolom yang relevan untuk proyek kita\n",
        "    df_final = df_reviews[['content', 'score', 'at']].copy()\n",
        "    df_final.rename(columns={'content': 'review_text', 'score': 'rating', 'at': 'review_date'}, inplace=True)\n",
        "\n",
        "    # Membersihkan data dari baris yang tidak memiliki teks ulasan\n",
        "    df_final.dropna(subset=['review_text'], inplace=True)\n",
        "\n",
        "    # Menghapus ulasan yang duplikat\n",
        "    df_final.drop_duplicates(subset=['review_text'], keep='first', inplace=True)\n",
        "\n",
        "    logging.info(f\"Berhasil mengumpulkan {len(df_final)} ulasan unik.\")\n",
        "\n",
        "    # Menyimpan DataFrame ke file CSV di lingkungan Colab\n",
        "    df_final.to_csv(OUTPUT_FILENAME, index=False, encoding='utf-8')\n",
        "\n",
        "    logging.info(f\"Dataset berhasil disimpan sebagai '{OUTPUT_FILENAME}'.\")\n",
        "\n",
        "    # Menampilkan 5 baris pertama dari dataset\n",
        "    print(\"\\nBerikut adalah 5 sampel data pertama:\")\n",
        "    print(df_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnLOuT_KPok2",
        "outputId": "1ad70f35-d966-41c3-c04a-8f10a2c3b0ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Berikut adalah 5 sampel data pertama:\n",
            "                                         review_text  rating  \\\n",
            "0  maaf kk semua player sekalu afk terus dan saya...       1   \n",
            "1                           DARK SYSTEM SEMUA ISINYA       1   \n",
            "2                           kurangin dark sistem nya       5   \n",
            "3  apalah ini game jaringan bagus, udah pake wifi...       1   \n",
            "4  nontonn ajing buat meta line banyak drak siste...       1   \n",
            "\n",
            "          review_date  \n",
            "0 2025-06-25 17:20:47  \n",
            "1 2025-06-25 17:20:44  \n",
            "2 2025-06-25 17:20:31  \n",
            "3 2025-06-25 17:20:21  \n",
            "4 2025-06-25 17:19:11  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pra-pemrosesan Data dan Labeling"
      ],
      "metadata": {
        "id": "idwbx0A7R_If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset yang sudah di-scrape sebelumnya\n",
        "try:\n",
        "    df = pd.read_csv('mobile_legends_reviews.csv')\n",
        "    print(\"Dataset berhasil dimuat!\")\n",
        "    print(f\"Jumlah data: {len(df)} ulasan.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"File 'mobile_legends_reviews.csv' tidak ditemukan. Pastikan Anda sudah menjalankan cell scraping.\")\n",
        "\n",
        "# Membuat fungsi untuk melabeli sentimen berdasarkan rating\n",
        "def label_sentiment(rating):\n",
        "    if rating in [1, 2]:\n",
        "        return 'Negatif'\n",
        "    elif rating == 3:\n",
        "        return 'Netral'\n",
        "    elif rating in [4, 5]:\n",
        "        return 'Positif'\n",
        "    return None # Jika ada rating di luar 1-5\n",
        "\n",
        "# Terapkan fungsi ke kolom 'rating' untuk membuat kolom 'sentiment'\n",
        "df['sentiment'] = df['rating'].apply(label_sentiment)\n",
        "\n",
        "# Memeriksa hasil pelabelan dan distribusi data\n",
        "print(\"\\nDistribusi data berdasarkan sentimen:\")\n",
        "print(df['sentiment'].value_counts())\n",
        "\n",
        "# Menampilkan 5 sampel data dengan kolom baru\n",
        "print(\"\\nBerikut adalah 5 sampel data dengan label sentimen:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me358Y3jSH1Y",
        "outputId": "f43ac8d6-1c53-4f29-e480-5fadf9816025"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset berhasil dimuat!\n",
            "Jumlah data: 11220 ulasan.\n",
            "\n",
            "Distribusi data berdasarkan sentimen:\n",
            "sentiment\n",
            "Negatif    7333\n",
            "Positif    3271\n",
            "Netral      616\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Berikut adalah 5 sampel data dengan label sentimen:\n",
            "                                         review_text  rating  \\\n",
            "0  maaf kk semua player sekalu afk terus dan saya...       1   \n",
            "1                           DARK SYSTEM SEMUA ISINYA       1   \n",
            "2                           kurangin dark sistem nya       5   \n",
            "3  apalah ini game jaringan bagus, udah pake wifi...       1   \n",
            "4  nontonn ajing buat meta line banyak drak siste...       1   \n",
            "\n",
            "           review_date sentiment  \n",
            "0  2025-06-25 17:20:47   Negatif  \n",
            "1  2025-06-25 17:20:44   Negatif  \n",
            "2  2025-06-25 17:20:31   Positif  \n",
            "3  2025-06-25 17:20:21   Negatif  \n",
            "4  2025-06-25 17:19:11   Negatif  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Cleaning"
      ],
      "metadata": {
        "id": "pYw2QtuoSnAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi tqdm untuk integrasi dengan pandas\n",
        "tqdm.pandas()\n",
        "\n",
        "# --- 1. Case Folding ---\n",
        "def case_folding(text):\n",
        "    return text.lower()\n",
        "\n",
        "# --- 2. Normalisasi Kata & Pembersihan Karakter ---\n",
        "# Membuat dictionary untuk normalisasi kata-kata slang/jargon\n",
        "normalization_dict = {\n",
        "    'gk': 'tidak', 'ga': 'tidak', 'gak': 'tidak', 'nggak': 'tidak',\n",
        "    'jg': 'juga', 'jgn': 'jangan', 'sdh': 'sudah',\n",
        "    'yg': 'yang', 'dg': 'dengan', 'tp': 'tapi',\n",
        "    'bgt': 'banget', 'utk': 'untuk',\n",
        "    'afk': 'away from keyboard', 'mabar': 'main bareng', 'lag': 'lambat',\n",
        "    'op': 'overpowered', 'gg': 'good game', 'plis': 'please',\n",
        "    'hp': 'handphone', 'mntp': 'mantap', 'keren': 'bagus'\n",
        "    # Tambahkan kata lain jika ditemukan saat eksplorasi data\n",
        "}\n",
        "\n",
        "def normalize_and_clean(text):\n",
        "    # Hapus URL\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    # Hapus karakter non-alphanumeric (kecuali spasi)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Normalisasi kata\n",
        "    words = text.split()\n",
        "    normalized_words = [normalization_dict.get(word, word) for word in words]\n",
        "    return ' '.join(normalized_words)\n",
        "\n",
        "# --- 3. Stopword Removal ---\n",
        "# Membuat stopword remover\n",
        "stopword_factory = StopWordRemoverFactory()\n",
        "# Menambahkan beberapa stopword yang mungkin relevan dengan konteks game\n",
        "more_stopwords = ['moonton', 'mobile', 'legend', 'legends', 'bang']\n",
        "data_stopwords = stopword_factory.get_stop_words() + more_stopwords\n",
        "remover = stopword_factory.create_stop_word_remover()\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return remover.remove(text)\n",
        "\n",
        "# --- 4. Stemming ---\n",
        "# Membuat stemmer\n",
        "stemmer_factory = StemmerFactory()\n",
        "stemmer = stemmer_factory.create_stemmer()\n",
        "\n",
        "def stem_text(text):\n",
        "    return stemmer.stem(text)\n",
        "\n",
        "# --- Gabungkan semua fungsi menjadi satu pipeline ---\n",
        "def preprocess_text(text):\n",
        "    text = case_folding(text)\n",
        "    text = normalize_and_clean(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = stem_text(text)\n",
        "    return text\n",
        "\n",
        "# --- Terapkan pipeline ke kolom 'review_text' ---\n",
        "# Proses ini mungkin memakan waktu beberapa menit. Tqdm akan menunjukkan progress bar.\n",
        "print(\"Memulai proses text cleaning...\")\n",
        "df['cleaned_review'] = df['review_text'].progress_apply(preprocess_text)\n",
        "print(\"Proses text cleaning selesai.\")\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"\\nContoh hasil pembersihan teks:\")\n",
        "print(df[['review_text', 'cleaned_review']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEwwAtcQSqAq",
        "outputId": "9dcb8b18-6bc2-45f4-cd76-ef355848d544"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai proses text cleaning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11220/11220 [25:46<00:00,  7.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proses text cleaning selesai.\n",
            "\n",
            "Contoh hasil pembersihan teks:\n",
            "                                         review_text  \\\n",
            "0  maaf kk semua player sekalu afk terus dan saya...   \n",
            "1                           DARK SYSTEM SEMUA ISINYA   \n",
            "2                           kurangin dark sistem nya   \n",
            "3  apalah ini game jaringan bagus, udah pake wifi...   \n",
            "4  nontonn ajing buat meta line banyak drak siste...   \n",
            "\n",
            "                                      cleaned_review  \n",
            "0  maaf kk semua player sekalu away from keyboard...  \n",
            "1                              dark system semua isi  \n",
            "2                             rangin dark sistem nya  \n",
            "3  apa game jaring bagus udah pake wifi tetep aja...  \n",
            "4  nontonn ajing buat meta line banyak drak siste...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}